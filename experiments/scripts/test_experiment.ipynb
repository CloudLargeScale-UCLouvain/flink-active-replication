{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: importnb in /opt/conda/lib/python3.8/site-packages (0.7.0)\n",
      "Requirement already satisfied: ipywidgets in /opt/conda/lib/python3.8/site-packages (7.5.1)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (4.3.3)\n",
      "Requirement already satisfied: nbformat>=4.2.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.0.7)\n",
      "Requirement already satisfied: widgetsnbextension~=3.5.0 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (3.5.1)\n",
      "Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (7.17.0)\n",
      "Requirement already satisfied: ipykernel>=4.5.1 in /opt/conda/lib/python3.8/site-packages (from ipywidgets) (5.3.4)\n",
      "Requirement already satisfied: ipython-genutils in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.1->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.1->ipywidgets) (4.4.2)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.8/site-packages (from traitlets>=4.3.1->ipywidgets) (1.15.0)\n",
      "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (3.2.0)\n",
      "Requirement already satisfied: jupyter-core in /opt/conda/lib/python3.8/site-packages (from nbformat>=4.2.0->ipywidgets) (4.6.3)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.8/site-packages (from widgetsnbextension~=3.5.0->ipywidgets) (6.0.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (3.0.5)\n",
      "Requirement already satisfied: setuptools>=18.5 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (49.2.1.post20200802)\n",
      "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (4.8.0)\n",
      "Requirement already satisfied: jedi>=0.10 in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.17.2)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (2.6.1)\n",
      "Requirement already satisfied: pickleshare in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.5)\n",
      "Requirement already satisfied: backcall in /opt/conda/lib/python3.8/site-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: jupyter-client in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.1.6)\n",
      "Requirement already satisfied: tornado>=4.2 in /opt/conda/lib/python3.8/site-packages (from ipykernel>=4.5.1->ipywidgets) (6.0.4)\n",
      "Requirement already satisfied: pyrsistent>=0.14.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (0.16.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /opt/conda/lib/python3.8/site-packages (from jsonschema!=2.5.0,>=2.4->nbformat>=4.2.0->ipywidgets) (19.3.0)\n",
      "Requirement already satisfied: nbconvert in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (5.6.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (19.0.2)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.11.2)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.0)\n",
      "Requirement already satisfied: Send2Trash in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.5.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.8/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.8/site-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: parso<0.8.0,>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from jedi>=0.10->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets) (0.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/lib/python3.8/site-packages (from jupyter-client->ipykernel>=4.5.1->ipywidgets) (2.8.1)\n",
      "Requirement already satisfied: bleach in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (3.1.5)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.4.2)\n",
      "Requirement already satisfied: testpath in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.4.4)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.6.0)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.3)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /opt/conda/lib/python3.8/site-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /opt/conda/lib/python3.8/site-packages (from jinja2->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (1.1.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (20.4)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.8/site-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (0.5.1)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets) (2.4.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install importnb \n",
    "!pip install ipywidgets \n",
    "#!jupyter nbextension enable --py widgetsnbextension\n",
    "#!jupyter labextension install @jupyter-widgets/jupyterlab-manager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymongo in /opt/conda/lib/python3.8/site-packages (3.11.0)\n"
     ]
    }
   ],
   "source": [
    "from importnb import Notebook\n",
    "with __import__('importnb').Notebook():\n",
    "    from scripts import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "from tqdm.notebook import tqdm as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import pprint\n",
    "import traceback\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_job_id(flink_address):\n",
    "    print(\"Running get_current_job_id in \" + flink_address)\n",
    "    out = subprocess.check_output(\"set -e pipefail && curl -s {flink_address}/jobs/ | jq '.jobs[].id' | tr -d '\\\"'\".format(flink_address=flink_address),\n",
    "                                   shell=True)\n",
    "    print(out)\n",
    "    print(\"Finished get_current_job_id is %s\" % out.decode(\"UTF-8\").strip())\n",
    "\n",
    "    return out.decode(\"UTF-8\").strip()\n",
    "\n",
    "def rescale(number):\n",
    "    print(\"Clean logs and old job artifacts\")\n",
    "    run_command(\"kubectl scale deployment -n default flink-jobmanager --replicas=0\", shell=False)\n",
    "    run_command(\"kubectl scale deployment -n default flink-taskmanager --replicas=0\", shell=False)\n",
    "    time.sleep(5)\n",
    "    run_command(\"kubectl scale deployment -n default flink-jobmanager --replicas=1\", shell=False)\n",
    "    run_command(\"kubectl scale deployment -n default flink-taskmanager --replicas={}\".format(number), shell=False)\n",
    "    time.sleep(60)\n",
    "    return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install_chart(path, name, params, timeout=\"180s\"):\n",
    "    with cd(path):\n",
    "        param_str = \"\"\n",
    "        for k in params.keys():\n",
    "            param_str += \"--set {}={} \".format(str(k).replace(\"!\",\".\"), str(params[k]).replace(\"!\",\".\"))\n",
    "        command = \"helm install {}  . {} --wait  --namespace default --timeout {} \".format(name, param_str, timeout)\n",
    "        result = run_command(command, log = shell_log)\n",
    "        return result   \n",
    "def uninstall_chart(path, name, timeout=\"120s\"):\n",
    "    with cd(path):\n",
    "        result = run_command(\"helm delete {} --namespace default\".format(name), log = shell_log)\n",
    "        print(result)\n",
    "        if result == \"0\":\n",
    "            sleep(timeout)\n",
    "    return result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reinstall(install_name, version, params=None):\n",
    "    uninstall_chart(\"../charts/flink\", install_name)\n",
    "    sleep(60)\n",
    "    if params is None:\n",
    "        params = {\n",
    "            \"image!tag\":version\n",
    "        }\n",
    "    install_chart(\"../charts/flink\", install_name, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def install(version, params=None):\n",
    "    install_name = \"flink\" \n",
    "    if params is None:\n",
    "        params = dict(default_params_flink)\n",
    "    params[\"image!tag\"] = version\n",
    "    reinstall(install_name, version, params)\n",
    "    \n",
    "def test(chart_name,bucket=None, default_params=None, specific_params={}, taskmanager_quantity=30, no_rescale=False):\n",
    "   \n",
    "    if default_params is None:\n",
    "        return None\n",
    "    \n",
    "    params = default_params.copy()\n",
    "    for name in specific_params:\n",
    "        params[name] = specific_params[name]\n",
    "    print(params)\n",
    "    params[\"bucket\"] = bucket\n",
    "\n",
    "    uninstall_chart(\"../charts/flink-job\", chart_name)\n",
    "    if not no_rescale:\n",
    "        rescale(taskmanager_quantity)\n",
    "        sleep(60)\n",
    "    \n",
    "    install_chart(\"../charts/flink-job\", chart_name, params)\n",
    "    ret = run_command(\"kubectl -n default wait --for=condition=complete --timeout={}s job/{}\".format(600, chart_name + \"-flink-job-retrieve\"))\n",
    "    \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "shell_log = False\n",
    "default_params_flink = {\n",
    "    \"taskmanager!replicaCount\": 1,\n",
    "    \"hdfs!persistence!nameNode!storageClass\": \"local-path\",\n",
    "    \"hdfs!persistence!dataNode!storageClass\": \"local-path\",\n",
    "    \"hdfs!persistence!nameNode!size\": \"5Gi\",\n",
    "    \"hdfs!persistence!dataNode!size\": \"5Gi\",\n",
    "    \"zookeeper!persistence!storageClass\": \"local-path\",\n",
    "    \"kafka!persistence!storageClass\": \"local-path\",\n",
    "    \"hdfs!enabled\":\"false\"\n",
    "}\n",
    "\n",
    "duration = 120\n",
    "default_params_ar = {\n",
    "    #\"testName\":test_name,\n",
    "    #\"bucket\":\"increasing-length3\",\n",
    "    #\"algorithm\": algorithm,\n",
    "    \"image!tag\": \"1.7.2-ar\",\n",
    "    \"installKafka\": \"false\",\n",
    "    \"job!jobClass\":\"me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob\",\n",
    "    \"job!length\":1,\n",
    "    \"job!duration\": duration,\n",
    "    \"job!mapParallelism\": \"2\",\n",
    "    \"algorithm!checkpointing\":\"false\",\n",
    "    \"algorithm!stateBackend\":\"rocksdb\",\n",
    "    \"algorithm!idleMarks\": \"true\",\n",
    "    \"job!sharingGroup\":\"true\",\n",
    "    \"installHdfs\":\"true\",\n",
    "    \"job!bufferTimeout\": 5\n",
    "}  \n",
    "default_params_vanilla = {\n",
    "    #\"testName\":test_name,\n",
    "    #\"bucket\":\"increasing-length3\",\n",
    "    \"image!tag\": \"1.7.2-baseline\",\n",
    "    \"installKafka\": \"false\",\n",
    "    \"algorithm!type\": \"VANILLA\",\n",
    "    \"job!jobClass\":\"me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob\",\n",
    "    \"job!length\":1,\n",
    "    \"job!duration\": duration,\n",
    "    \"job!mapParallelism\": \"2\",\n",
    "    \"algorithm!checkpointing\":\"true\",\n",
    "    \"algorithm!stateBackend\":\"rocksdb\",\n",
    "    \"algorithm!idleMarks\": \"false\",\n",
    "    \"job!sharingGroup\":\"true\",\n",
    "    \"killTaskManager!waitForKill\": \"True\",\n",
    "    \"installHdfs\":\"true\",\n",
    "    \"job!bufferTimeout\": 5    \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## parameters initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VANILLA NO CHECKPOINTING\n",
    "params_vanilla_nocp = dict(default_params_vanilla)\n",
    "params_vanilla_nocp[\"name_algorithm\"] = \"nc\"\n",
    "params_vanilla_nocp[\"algorithm!type\"] = \"VANILLA_NOCP\"\n",
    "params_vanilla_nocp[\"algorithm!checkpointing\"] = \"false\"\n",
    "# VANILLA CHECKPOINTING\n",
    "params_vanilla = dict(default_params_vanilla)\n",
    "params_vanilla[\"name_algorithm\"] = \"cp\"\n",
    "params_vanilla[\"algorithm!type\"] = \"VANILLA\"\n",
    "params_vanilla[\"installHdfs\"] = \"true\"\n",
    "# ACTIVE_REPLICATION NO_ORDERING\n",
    "params_ar_noordering = dict(default_params_ar)\n",
    "params_ar_noordering[\"name_algorithm\"] = \"no\"\n",
    "params_ar_noordering[\"algorithm!type\"] = \"NO_ORDERING\"\n",
    "# ACTIVE_REPLICATION BETTER_BIAS\n",
    "params_ar_betterbias = dict(default_params_ar)\n",
    "params_ar_betterbias[\"name_algorithm\"] = \"tm\"\n",
    "params_ar_betterbias[\"algorithm!type\"] = \"BETTER_BIAS\"\n",
    "params_ar_betterbias[\"algorithm!idleMarksInterval\"] = 25\n",
    "# ACTIVE_REPLICATION BETTER_BIAS \n",
    "params_ar_betterbias_nosp = dict(default_params_ar)\n",
    "params_ar_betterbias_nosp[\"name_algorithm\"] = \"tm\"\n",
    "params_ar_betterbias_nosp[\"algorithm!type\"] = \"BETTER_BIAS\"\n",
    "params_ar_betterbias_nosp[\"algorithm!idleMarks\"] = \"false\"\n",
    "\n",
    "# ACTIVE_REPLICATION LEADER_KAFKA\n",
    "params_ar_leader_kafka = dict(default_params_ar)\n",
    "params_ar_betterbias_nosp[\"algorithm!idleMarks\"] = \"false\"\n",
    "params_ar_leader_kafka[\"name_algorithm\"] = \"ka\"\n",
    "params_ar_leader_kafka[\"algorithm!type\"] = \"LEADER_KAFKA\"\n",
    "params_ar_leader_kafka[\"installKafka\"] = \"true\"\n",
    "\n",
    "# kill Leader\n",
    "params_ar_leader_kafka_kill_leader = dict(params_ar_leader_kafka)\n",
    "params_ar_leader_kafka_kill_leader[\"killTaskManager!kazooTarget\"] = \"leader\"\n",
    "params_ar_leader_kafka_kill_follower = dict(params_ar_leader_kafka)\n",
    "params_ar_leader_kafka_kill_follower[\"killTaskManager!kazooTarget\"] = \"follower\"\n",
    "\n",
    "# liverobin\n",
    "params_ar_liverobin = dict(default_params_ar)\n",
    "params_ar_liverobin[\"algorithm!type\"] = \"LIVE_ROBIN\" \n",
    "params_ar_liverobin[\"algorithm!liveRobinMarks\"] = \"true\" \n",
    "params_ar_liverobin[\"algorithm!idleMarks\"] = \"false\" \n",
    "params_ar_liverobin[\"name_algorithm\"] = \"lr\"\n",
    "params_ar_liverobin[\"installKafka\"] = \"true\"\n",
    "params_ar_liverobin[\"algorithm!heartbeatEmitter!enabled\"] = \"true\"\n",
    "params_ar_liverobin[\"algorithm!liveRobinMarksInterval\"] = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helm dep update\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test high 99th percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3a9ddca2f0a4abc9541095b44294d47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helm delete flink --namespace default\n",
      "0\n",
      "helm install flink  . --set taskmanager.replicaCount=1 --set hdfs.persistence.nameNode.storageClass=local-path --set hdfs.persistence.dataNode.storageClass=local-path --set hdfs.persistence.nameNode.size=5Gi --set hdfs.persistence.dataNode.size=5Gi --set zookeeper.persistence.storageClass=local-path --set kafka.persistence.storageClass=local-path --set hdfs.enabled=true --set kafka.enabled=false --set zookeeper.enabled=false --set image.tag=1.7.2-baseline  --wait  --namespace default --timeout 180s \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4718496f2334bc98f8b39c962181ddd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9707f9c3dd24d32b9c77e02a1009c2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image!tag': '1.7.2-baseline', 'installKafka': 'false', 'algorithm!type': 'VANILLA', 'job!jobClass': 'me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob', 'job!length': 1, 'job!duration': 120, 'job!mapParallelism': '2', 'algorithm!checkpointing': 'true', 'algorithm!stateBackend': 'rocksdb', 'algorithm!idleMarks': 'false', 'job!sharingGroup': 'true', 'killTaskManager!waitForKill': 'True', 'installHdfs': 'true', 'job!bufferTimeout': 5, 'name_algorithm': 'cp', 'algorithm!liveRobinMarksInterval': 0, 'job!latencyTrackingInterval': '25'}\n",
      "helm delete test-cp-1-0-0 --namespace default\n",
      "1\n",
      "Clean logs and old job artifacts\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "Log 0 - 2021-08-09 20:22:39 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "Log 0 - 2021-08-09 20:22:39 : deployment.apps/flink-taskmanager scaled\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "Log 0 - 2021-08-09 20:22:44 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=2\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=2\n",
      "Log 0 - 2021-08-09 20:22:44 : deployment.apps/flink-taskmanager scaled\n",
      "helm install test-cp-1-0-0  . --set image.tag=1.7.2-baseline --set installKafka=false --set algorithm.type=VANILLA --set job.jobClass=me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob --set job.length=1 --set job.duration=120 --set job.mapParallelism=2 --set algorithm.checkpointing=true --set algorithm.stateBackend=rocksdb --set algorithm.idleMarks=false --set job.sharingGroup=true --set killTaskManager.waitForKill=True --set installHdfs=true --set job.bufferTimeout=5 --set name_algorithm=cp --set algorithm.liveRobinMarksInterval=0 --set job.latencyTrackingInterval=25 --set bucket=test  --wait  --namespace default --timeout 180s \n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/test-cp-1-0-0-flink-job-retrieve\n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/test-cp-1-0-0-flink-job-retrieve\n",
      "Log 0 - 2021-08-09 20:34:47 : error: timed out waiting for the condition on jobs/test-cp-1-0-0-flink-job-retrieve\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucket = \"test\"\n",
    "length = 1\n",
    "\n",
    "test_maps = [params_vanilla]\n",
    "\n",
    "interval=0\n",
    "for test_map in tqdm(test_maps):\n",
    "    flink_params = dict(default_params_flink)\n",
    "    flink_params[\"kafka!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"zookeeper!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"hdfs!enabled\"] = test_map[\"installHdfs\"]    \n",
    "    install(test_map[\"image!tag\"], flink_params)\n",
    "    for length in tqdm([1]):    \n",
    "        for index in tqdm(range(1)):\n",
    "            test(\"test-{}-{}-{}-{}\".format(test_map[\"name_algorithm\"], length, interval, index),\n",
    "                 bucket,\n",
    "                 test_map,\n",
    "                 {\n",
    "                   \"job!length\":length,\n",
    "                    \"algorithm!liveRobinMarksInterval\" : interval,\n",
    "                    \"job!latencyTrackingInterval\": \"25\",\n",
    "                 },\n",
    "                 no_rescale=False,\n",
    "                 taskmanager_quantity=2\n",
    "                )  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# liverobintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ed05606d0c3462da42e2276869ce359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helm delete flink --namespace default\n",
      "1\n",
      "helm install flink  . --set taskmanager.replicaCount=1 --set hdfs.persistence.nameNode.storageClass=local-path --set hdfs.persistence.dataNode.storageClass=local-path --set hdfs.persistence.nameNode.size=5Gi --set hdfs.persistence.dataNode.size=5Gi --set zookeeper.persistence.storageClass=local-path --set kafka.persistence.storageClass=local-path --set hdfs.enabled=true --set kafka.enabled=true --set zookeeper.enabled=true --set image.tag=1.7.2-ar  --wait  --namespace default --timeout 180s \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01b510f85bb24477916b6a6aa0e06e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171d363e2e874cbfb5c79c0591a8031a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=4.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "988db0f9375d4c37958cfb56090215b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=5.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image!tag': '1.7.2-ar', 'installKafka': 'true', 'job!jobClass': 'me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob', 'job!length': 1, 'job!duration': 120, 'job!mapParallelism': '2', 'algorithm!checkpointing': 'false', 'algorithm!stateBackend': 'rocksdb', 'algorithm!idleMarks': 'false', 'job!sharingGroup': 'true', 'installHdfs': 'true', 'job!bufferTimeout': 5, 'algorithm!type': 'LIVE_ROBIN', 'algorithm!liveRobinMarks': 'true', 'name_algorithm': 'lr', 'algorithm!heartbeatEmitter!enabled': 'true', 'algorithm!liveRobinMarksInterval': 5}\n",
      "helm delete mb1-lr-1-5-0 --namespace default\n",
      "1\n",
      "Clean logs and old job artifacts\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "Log 0 - 2021-06-29 22:30:19 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "Log 0 - 2021-06-29 22:30:19 : deployment.apps/flink-taskmanager scaled\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "Log 0 - 2021-06-29 22:30:25 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "Log 0 - 2021-06-29 22:30:25 : deployment.apps/flink-taskmanager scaled\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-157e54530c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0minterval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m                 test(\"mb1-{}-{}-{}-{}\".format(test_map[\"name_algorithm\"], length, interval, index),\n\u001b[0m\u001b[1;32m     15\u001b[0m                      \u001b[0mbucket\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                      \u001b[0mtest_map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-1c3525e39070>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(chart_name, bucket, default_params, specific_params, taskmanager_quantity, no_rescale)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0muninstall_chart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../charts/flink-job\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchart_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_rescale\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mrescale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtaskmanager_quantity\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-483738e6b9fa>\u001b[0m in \u001b[0;36mrescale\u001b[0;34m(number)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kubectl scale deployment -n default flink-jobmanager --replicas=1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mrun_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"kubectl scale deployment -n default flink-taskmanager --replicas={}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m60\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bucket = \"liverobin-testt\"\n",
    "length = 1\n",
    "test_maps = [params_ar_liverobin]\n",
    "#test_maps = [params_ar_leader_kafka]\n",
    "for test_map in tqdm(test_maps):\n",
    "    flink_params = dict(default_params_flink)\n",
    "    flink_params[\"kafka!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"zookeeper!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"hdfs!enabled\"] = test_map[\"installHdfs\"]    \n",
    "    install(test_map[\"image!tag\"], flink_params)\n",
    "    for length in tqdm(range(1,5)):    \n",
    "        for interval in tqdm([5,10,50,100]):\n",
    "            for index in tqdm(range(5)):\n",
    "                test(\"mb1-{}-{}-{}-{}\".format(test_map[\"name_algorithm\"], length, interval, index),\n",
    "                     bucket,\n",
    "                     test_map,\n",
    "                     {\n",
    "                       \"job!length\":length,\n",
    "                        \"algorithm!liveRobinMarksInterval\" : interval                     \n",
    "                     },\n",
    "                     no_rescale=False,\n",
    "                     taskmanager_quantity=29\n",
    "                    )  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image!tag': '1.7.2-ar', 'installKafka': 'true', 'job!jobClass': 'me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob', 'job!length': 1, 'job!duration': 120, 'job!mapParallelism': '2', 'algorithm!checkpointing': 'false', 'algorithm!stateBackend': 'rocksdb', 'algorithm!idleMarks': 'false', 'job!sharingGroup': 'true', 'installHdfs': 'true', 'algorithm!type': 'LIVE_ROBIN', 'algorithm!liveRobinMarks': 'true', 'name_algorithm': 'lr', 'algorithm!heartbeatEmitter!enabled': 'true', 'job!rate': 1000}\n",
      "helm delete lr-lr-1-0 --namespace default\n",
      "0\n",
      "helm install lr-lr-1-0  . --set image.tag=1.7.2-ar --set installKafka=true --set job.jobClass=me.florianschmidt.microbenchmark.jobs.IncreasingLengthJob --set job.length=1 --set job.duration=120 --set job.mapParallelism=2 --set algorithm.checkpointing=false --set algorithm.stateBackend=rocksdb --set algorithm.idleMarks=false --set job.sharingGroup=true --set installHdfs=true --set algorithm.type=LIVE_ROBIN --set algorithm.liveRobinMarks=true --set name_algorithm=lr --set algorithm.heartbeatEmitter.enabled=true --set job.rate=1000 --set bucket=liverobintest  --wait  --namespace default --timeout 180s \n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/lr-lr-1-0-flink-job-retrieve\n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/lr-lr-1-0-flink-job-retrieve\n",
      "Log 0 - 2021-04-08 11:53:07 : job.batch/lr-lr-1-0-flink-job-retrieve condition met\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(\"lr-{}-{}-{}\".format(test_map[\"name_algorithm\"], length, index),\n",
    "     bucket,\n",
    "     test_map,\n",
    "     {\n",
    "       \"job!length\":length,\n",
    "       \"job!rate\":1000,\n",
    "     },\n",
    "     no_rescale=True,\n",
    "     taskmanager_quantity=29\n",
    "    )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'params_ar_liverobin' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-63a8c4c3f718>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbucket\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"liverobintest\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlength\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_maps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mparams_ar_liverobin\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#test_maps = [params_ar_leader_kafka]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtest_map\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_maps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'params_ar_liverobin' is not defined"
     ]
    }
   ],
   "source": [
    "bucket = \"liverobintest\"\n",
    "length = 1\n",
    "test_maps = [params_ar_liverobin]\n",
    "#test_maps = [params_ar_leader_kafka]\n",
    "for test_map in tqdm(test_maps):\n",
    "    flink_params = dict(default_params_flink)\n",
    "    flink_params[\"kafka!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"zookeeper!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"hdfs!enabled\"] = test_map[\"installHdfs\"]    \n",
    "    install(test_map[\"image!tag\"], flink_params)\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "403192b7fef94319a9185e3e7d4a4a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6c9566bcd004e24bc51bdca8ada33ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image!tag': '1.7.2-ar', 'installKafka': 'true', 'job!jobClass': 'me.florianschmidt.microbenchmark.jobs.ThreeSourcesJob', 'job!length': 2, 'job!duration': 120, 'job!mapParallelism': '2', 'algorithm!checkpointing': 'false', 'algorithm!stateBackend': 'rocksdb', 'algorithm!idleMarks': 'false', 'job!sharingGroup': 'true', 'installHdfs': 'true', 'algorithm!type': 'LIVE_ROBIN', 'algorithm!liveRobinMarks': 'true', 'name_algorithm': 'lr', 'retrieveScript!getAllSinks': 'true', 'job!rate': 1, 'job!rate2': 1}\n",
      "helm delete lr-lr-2-0 --namespace default\n",
      "0\n",
      "Clean logs and old job artifacts\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "Log 0 - 2021-04-07 08:09:51 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "Log 0 - 2021-04-07 08:09:51 : deployment.apps/flink-taskmanager scaled\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "Log 0 - 2021-04-07 08:09:57 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "Log 0 - 2021-04-07 08:09:57 : deployment.apps/flink-taskmanager scaled\n",
      "helm install lr-lr-2-0  . --set image.tag=1.7.2-ar --set installKafka=true --set job.jobClass=me.florianschmidt.microbenchmark.jobs.ThreeSourcesJob --set job.length=2 --set job.duration=120 --set job.mapParallelism=2 --set algorithm.checkpointing=false --set algorithm.stateBackend=rocksdb --set algorithm.idleMarks=false --set job.sharingGroup=true --set installHdfs=true --set algorithm.type=LIVE_ROBIN --set algorithm.liveRobinMarks=true --set name_algorithm=lr --set retrieveScript.getAllSinks=true --set job.rate=1 --set job.rate2=1 --set bucket=liverobintest  --wait  --namespace default --timeout 180s \n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/lr-lr-2-0-flink-job-retrieve\n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/lr-lr-2-0-flink-job-retrieve\n",
      "Log 0 - 2021-04-07 08:15:28 : job.batch/lr-lr-2-0-flink-job-retrieve condition met\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for length in tqdm(range(2,3)):    \n",
    "    for index in tqdm(range(1)):\n",
    "        test(\"lr-{}-{}-{}\".format(test_map[\"name_algorithm\"], length, index),\n",
    "             bucket,\n",
    "             test_map,\n",
    "             {\n",
    "               \"job!length\":length,\n",
    "                \"retrieveScript!getAllSinks\":\"true\",\n",
    "                \"job!jobClass\":\"me.florianschmidt.microbenchmark.jobs.ThreeSourcesJob\",  \n",
    "                \"job!rate\":1000,\n",
    "                \"job!rate2\":1\n",
    "             },\n",
    "             no_rescale=False,\n",
    "             taskmanager_quantity=29\n",
    "            )   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32918df431894db89f188b12f53b7e4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helm delete flink --namespace default\n",
      "0\n",
      "helm install flink  . --set taskmanager.replicaCount=1 --set hdfs.persistence.nameNode.storageClass=local-path --set hdfs.persistence.dataNode.storageClass=local-path --set hdfs.persistence.nameNode.size=5Gi --set hdfs.persistence.dataNode.size=5Gi --set zookeeper.persistence.storageClass=local-path --set kafka.persistence.storageClass=local-path --set hdfs.enabled=true --set kafka.enabled=false --set zookeeper.enabled=false --set image.tag=1.7.2-ar  --wait  --namespace default --timeout 180s \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90c83f4e9134ac0b6b98a128e6cef45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7920e8e5092542f2801e11055b52683a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'image!tag': '1.7.2-ar', 'installKafka': 'false', 'job!jobClass': 'me.florianschmidt.examples.bettercloud.Job', 'job!length': 1, 'job!duration': 300, 'job!mapParallelism': '2', 'algorithm!checkpointing': 'false', 'algorithm!stateBackend': 'rocksdb', 'algorithm!idleMarks': 'false', 'job!sharingGroup': 'true', 'installHdfs': 'true', 'algorithm!type': 'LIVE_ROBIN', 'algorithm!liveRobinMarks': 'true', 'name_algorithm': 'lr', 'experimentationName': '2021-04-06-11-47-08-test-bettercloud-lr-0', 'workload!length': 1, 'workload!replicationFactor': 1, 'retrieveScript!getAllSinks': 'true', 'injector!enabled': 'true', 'injector!consumerRate': 100, 'injector!controlRate': 5, 'injector!seed': 1, 'algorithm!idleMarksInterval': 25, 'killTaskManager!enabled': 'true', 'killTaskManager!taskName': 'Qualifier', 'killTaskManager!killDelay': 150, 'killTaskManager!replicaIndex': 0, 'killTaskManager!operatorIndex': 0, 'killTaskManager!gracePeriod': 0}\n",
      "helm delete test0 --namespace default\n",
      "0\n",
      "Clean logs and old job artifacts\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=0\n",
      "Log 0 - 2021-04-06 11:47:29 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=0\n",
      "Log 0 - 2021-04-06 11:47:29 : deployment.apps/flink-taskmanager scaled\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "kubectl scale deployment -n default flink-jobmanager --replicas=1\n",
      "Log 0 - 2021-04-06 11:47:35 : deployment.apps/flink-jobmanager scaled\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "kubectl scale deployment -n default flink-taskmanager --replicas=29\n",
      "Log 0 - 2021-04-06 11:47:35 : deployment.apps/flink-taskmanager scaled\n",
      "helm install test0  . --set image.tag=1.7.2-ar --set installKafka=false --set job.jobClass=me.florianschmidt.examples.bettercloud.Job --set job.length=1 --set job.duration=300 --set job.mapParallelism=2 --set algorithm.checkpointing=false --set algorithm.stateBackend=rocksdb --set algorithm.idleMarks=false --set job.sharingGroup=true --set installHdfs=true --set algorithm.type=LIVE_ROBIN --set algorithm.liveRobinMarks=true --set name_algorithm=lr --set experimentationName=2021-04-06-11-47-08-test-bettercloud-lr-0 --set workload.length=1 --set workload.replicationFactor=1 --set retrieveScript.getAllSinks=true --set injector.enabled=true --set injector.consumerRate=100 --set injector.controlRate=5 --set injector.seed=1 --set algorithm.idleMarksInterval=25 --set killTaskManager.enabled=true --set killTaskManager.taskName=Qualifier --set killTaskManager.killDelay=150 --set killTaskManager.replicaIndex=0 --set killTaskManager.operatorIndex=0 --set killTaskManager.gracePeriod=0 --set bucket=test-bettercloud  --wait  --namespace default --timeout 180s \n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/test0-flink-job-retrieve\n",
      "kubectl -n default wait --for=condition=complete --timeout=600s job/test0-flink-job-retrieve\n",
      "Log 0 - 2021-04-06 11:56:20 : job.batch/test0-flink-job-retrieve condition met\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bucket = \"test-bettercloud\"\n",
    "length = 1\n",
    "#docker_tag = \"1.7.2-ar\"\n",
    "#test_maps = [params_vanilla, params_ar_betterbias, params_ar_leader_kafka, params_ar_leader_kafka, params_ar_leader_kafka]\n",
    "test_maps = [params_ar_liverobin]\n",
    "#test_maps = [params_vanilla, params_ar_betterbias]\n",
    "\n",
    "for test_map in tqdm(test_maps):\n",
    "    flink_params = dict(default_params_flink)\n",
    "    flink_params[\"kafka!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"zookeeper!enabled\"] = test_map[\"installKafka\"]\n",
    "    flink_params[\"hdfs!enabled\"] = test_map[\"installHdfs\"]    \n",
    "    install(test_map[\"image!tag\"], flink_params)    \n",
    "    for interval in [25]:\n",
    "        for user_rate in tqdm([100]):\n",
    "            for index in tqdm(range(1)):    \n",
    "                test_name = format(\"{}-{}-{}-{}\".format(datetime.today().strftime('%Y-%m-%d-%H-%M-%S'), bucket, test_map[\"name_algorithm\"], index))\n",
    "                test(\"test{}\".format(index),\n",
    "                     bucket,\n",
    "                     test_map,\n",
    "                     {\n",
    "                        \"experimentationName\": test_name,             \n",
    "                        \"workload!length\": 1,\n",
    "                        \"workload!replicationFactor\": 1,\n",
    "                        \"retrieveScript!getAllSinks\":\"true\",                     \n",
    "                        \"job!jobClass\":\"me.florianschmidt.examples.bettercloud.Job\",\n",
    "                        \"injector!enabled\":\"true\",\n",
    "                        \"injector!consumerRate\":user_rate,\n",
    "                        \"injector!controlRate\":5,\n",
    "                        \"injector!seed\": index + 1,\n",
    "                        \"algorithm!idleMarksInterval\": interval,                     \n",
    "                        \"job!duration\": 300,                 \n",
    "                        \"killTaskManager!enabled\": \"true\",\n",
    "                        \"killTaskManager!taskName\": \"Qualifier\",\n",
    "                        \"killTaskManager!killDelay\": 150,\n",
    "                        \"killTaskManager!replicaIndex\": 0,\n",
    "                        \"killTaskManager!operatorIndex\": 0,\n",
    "                        \"killTaskManager!gracePeriod\": 0             \n",
    "                     },\n",
    "                     no_rescale=False,\n",
    "                     taskmanager_quantity=29\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
